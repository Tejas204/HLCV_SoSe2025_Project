{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc41dc87",
   "metadata": {},
   "source": [
    "## Architecture code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76509c16",
   "metadata": {},
   "source": [
    "### CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0737aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# IMPORTS\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a4595f",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb7c7787",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e544fbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:15<00:00, 636kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 259kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:03<00:00, 428kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.92MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.MNIST(root='../data', train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.MNIST(root='../data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21adcddb",
   "metadata": {},
   "source": [
    "#### Branch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd4d1d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# @CLASS: CNN_ARCHITECTURE\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "class CNN_ARCHITECTURE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, activation, norm_layer, drop_prob=0.0):\n",
    "        super(CNN_ARCHITECTURE, self).__init__()\n",
    "\n",
    "        # Initialize variables\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.activation = activation\n",
    "        self.norm_layer = norm_layer\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "    \"\"\"-------------------------------------------------------------------------------------------------------------\n",
    "    @Function: build_model\n",
    "    @Args: self\n",
    "    @Returns: features\n",
    "    @Description: Create a CNN architecture that extracts the features from the input images\n",
    "    -------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "    def build_model(self):\n",
    "\n",
    "        layers = []\n",
    "        input_dim = self.input_size\n",
    "        for i in range(len(self.hidden_layers)):\n",
    "            # Add the convoluiton layer\n",
    "            layers.append(nn.Conv2d(input_dim, self.hidden_layers[i], 3, stride=1, padding=1))\n",
    "\n",
    "            # Add batch normalization\n",
    "            if self.norm_layer:\n",
    "                layers.append(self.norm_layer(self.hidden_layers[i]))\n",
    "            \n",
    "            # Add maxpooling, change this condition\n",
    "            if True:\n",
    "                layers.append(nn.MaxPool2d(2,2))\n",
    "            \n",
    "            # Add activation\n",
    "            layers.append(self.activation())\n",
    "\n",
    "            # Add dropout\n",
    "            if self.drop_prob:\n",
    "                layers.append(nn.Dropout(self.drop_prob))\n",
    "\n",
    "            input_dim = self.hidden_layers[i]\n",
    "        \n",
    "        self.features = nn.Sequential(*layers)\n",
    "\n",
    "    \"\"\"-------------------------------------------------------------------------------------------------------------\n",
    "    @Function: forward\n",
    "    @Args: \n",
    "        self: object\n",
    "        x: inputs\n",
    "    @Returns: features\n",
    "    @Description: Passes the input to the CNN architecture for feature extraction\n",
    "    -------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        return features\n",
    "    \n",
    "\n",
    "    \"\"\"-------------------------------------------------------------------------------------------------------------\n",
    "    @Function: image_denoising\n",
    "    @Args: \n",
    "        self: object\n",
    "    @Returns: denoised images\n",
    "    @Description: A denoising filter to remove the noise from the input images\n",
    "    -------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "    def image_denoising(self):\n",
    "        print(\"I am denoising\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0534c26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 512, 512]\n"
     ]
    }
   ],
   "source": [
    "cnn_experiment_1 = dict(\n",
    "    name = 'CNN_Experiment_1',\n",
    "\n",
    "    model_args = dict(\n",
    "        input_size = 3,\n",
    "        num_classes = 10,\n",
    "        hidden_layers = [128, 512, 512],\n",
    "        activation = nn.ReLU,\n",
    "        norm_layer = False,\n",
    "        drop_prob = 0.4,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# from configs.cnn_branch_config import cnn_experiment_1\n",
    "print(cnn_experiment_1['model_args']['hidden_layers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27631cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0856, 0.0000, 0.0000,  ..., 0.0202, 0.0000, 0.1317]])\n",
      "torch.Size([1, 401408])\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# DRIVER CODE\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# from configs.cnn_branch_config import cnn_experiment_1\n",
    "\n",
    "model = CNN_ARCHITECTURE(3, cnn_experiment_1['model_args']['hidden_layers'], cnn_experiment_1['model_args']['activation'], cnn_experiment_1['model_args']['norm_layer'], cnn_experiment_1['model_args']['drop_prob'])\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1,3,224,224)\n",
    "\n",
    "with torch.no_grad():\n",
    "    final_features = model(input)\n",
    "\n",
    "print(final_features)\n",
    "print(final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b9cad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HLCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
