{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e286120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# Imports\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd380b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# System path for imports\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "PROJECT_ROOT='./'\n",
    "import sys\n",
    "sys.path.append(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ae4d6",
   "metadata": {},
   "source": [
    "## Experiment 1: CNN + Transformer Hybrid Architecture\n",
    "\n",
    "Contains the hybrid architecture with element wise product of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce37e98c",
   "metadata": {},
   "source": [
    "### CNN-ViT Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c57e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# Training Loop\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def train(model, dataloader, optimizer, epochs=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for blurry, sharp in dataloader:\n",
    "            blurry = blurry.to(device)\n",
    "            sharp = sharp.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(blurry)\n",
    "            loss = criterion(output, sharp)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# Driver Code\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "from architecture.cnn_vit_hybrid_architecture import CNN_VIT_HYBRID_ARCHITECTURE\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "raw_image = Image.open(\"./Blur.png\").convert('RGB')\n",
    "image = transform(raw_image)\n",
    "\n",
    "\n",
    "model = CNN_VIT_HYBRID_ARCHITECTURE()\n",
    "model(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HLCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
