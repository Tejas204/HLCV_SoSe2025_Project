{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e286120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# Imports\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd380b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# System path for imports\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "PROJECT_ROOT='./'\n",
    "import sys\n",
    "sys.path.append(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ae4d6",
   "metadata": {},
   "source": [
    "## Experiment 1: CNN + Transformer Hybrid Architecture\n",
    "\n",
    "Contains the hybrid architecture with dot product of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f18e8e",
   "metadata": {},
   "source": [
    "### Branch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1eb3c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_ARCHITECTURE(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.4, inplace=False)\n",
      "  )\n",
      ")\n",
      "Input shape: torch.Size([3, 720, 1280])\n",
      "Final features: tensor([[0.0629, 0.0603, 0.0685,  ..., 0.0205, 0.0184, 0.0126],\n",
      "        [0.0086, 0.0225, 0.0224,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0962, 0.0855, 0.0843,  ..., 0.0395, 0.0397, 0.0375],\n",
      "        ...,\n",
      "        [0.0206, 0.0311, 0.0102,  ..., 0.0199, 0.0209, 0.0198],\n",
      "        [0.0319, 0.0018, 0.0046,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Final features shape: torch.Size([512, 14400])\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# Driver code\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "from architecture.cnn_architecture import CNN_ARCHITECTURE\n",
    "from configs.cnn_branch_config import cnn_experiment_1\n",
    "\n",
    "model = CNN_ARCHITECTURE(cnn_experiment_1['model_args']['input_size'], cnn_experiment_1['model_args']['hidden_layers'], cnn_experiment_1['model_args']['activation'], cnn_experiment_1['model_args']['norm_layer'], cnn_experiment_1['model_args']['drop_prob'])\n",
    "print(model)\n",
    "model.eval()\n",
    "\n",
    "# input_2 = torch.randn(1,3,224,224)\n",
    "image = Image.open(\"./Blur.png\").convert('RGB')\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "input = transform(image)\n",
    "print(f\"Input shape: {input.shape}\")\n",
    "\n",
    "cnn_out = model(input)\n",
    "\n",
    "print(f\"Final features: {cnn_out}\")\n",
    "print(f\"Final features shape: {cnn_out.shape}\")\n",
    "\n",
    "# features_in_shape = final_features.view(512, 28, 28)\n",
    "# print(features_in_shape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2650c44d",
   "metadata": {},
   "source": [
    "### Branch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feea971c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/HLCV/lib/python3.12/site-packages/transformers/models/vit/feature_extraction_vit.py:30: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cls': tensor([[ 4.7615e-01, -9.9602e-02,  1.5029e+00, -5.1744e-02, -3.8278e-02,\n",
      "          2.4302e+00,  4.4923e-01, -8.1642e-01, -5.7224e-01, -8.1522e-01,\n",
      "         -1.8054e+00, -1.4601e-01,  3.8230e-01,  6.0427e-01, -1.1726e-01,\n",
      "         -5.0949e-01, -3.7467e-01,  5.5540e-01,  1.0882e-01,  1.2580e+00,\n",
      "         -6.7239e-01, -7.0905e-01, -6.4983e-01, -1.4001e+00, -7.9707e-02,\n",
      "         -1.1794e+00, -5.2500e-01, -1.1217e+00,  8.0294e-01,  3.9371e-01,\n",
      "         -1.1232e+00,  9.5453e-01,  6.8784e-01, -2.0632e+00,  2.1795e-01,\n",
      "          3.2798e-01, -1.2843e+00,  1.1984e+00,  1.1486e+00, -4.5268e-01,\n",
      "         -5.7421e-01, -1.4203e+00,  1.3407e+00,  3.2471e-01, -1.5128e+00,\n",
      "         -3.7624e-01, -1.2511e+00, -1.4204e-01, -1.9368e+00,  9.1642e-01,\n",
      "          5.8074e-02,  1.0683e+00, -1.2409e+00,  5.7934e-01, -9.9048e-01,\n",
      "         -1.0262e+00,  5.2281e-01, -2.2733e-01,  1.8387e-01,  8.7814e-01,\n",
      "          1.9188e+00, -1.4181e+00,  8.1813e-02,  6.3443e-01,  4.7809e-01,\n",
      "         -1.6845e+00,  1.4446e-01, -2.8452e-01, -8.6317e-01,  6.2590e-01,\n",
      "         -2.0767e-01,  3.8888e-01, -6.0857e-02,  1.5167e+00, -1.3345e+00,\n",
      "          6.6638e-01,  1.6562e+00,  6.1493e-01, -6.7213e-01, -7.8377e-01,\n",
      "          5.4439e-01,  6.4337e-01, -4.1868e-01, -7.3031e-01, -2.9653e-02,\n",
      "         -1.9611e+00,  1.3014e-01, -2.7407e-01,  4.9458e-01,  1.6432e+00,\n",
      "         -3.8377e-01, -6.1723e-01,  1.5613e+00, -1.1694e-01, -3.7521e-01,\n",
      "         -5.8885e-01,  4.8805e-01,  3.1897e-01,  1.1579e+00,  6.2967e-01,\n",
      "         -2.1819e+00, -3.0916e-01,  7.8198e-03,  9.8708e-01, -9.3015e-01,\n",
      "          4.0767e-01, -1.9567e+00,  1.6322e+00,  5.6909e-01, -2.0722e-01,\n",
      "          6.2135e-01, -8.0937e-01, -2.8904e+00, -3.9944e-01,  4.4978e-01,\n",
      "          1.9912e+00,  3.0107e-01,  4.9161e-01,  8.7773e-01,  1.2983e-01,\n",
      "         -9.1981e-01,  6.4997e-01, -4.8919e-02, -2.1942e+00,  1.1721e-02,\n",
      "         -1.1846e+00, -1.7137e+00,  6.5833e-01, -5.0247e-01, -6.6470e-01,\n",
      "          2.7683e-01,  1.7931e-01, -6.6631e-01, -2.4476e-01, -4.1676e-01,\n",
      "         -3.0735e-01, -1.6268e+00, -2.4343e+00, -5.0267e-01,  2.4682e+00,\n",
      "          9.1382e-01,  8.3951e-01,  1.8388e-01,  4.5221e-01,  7.5467e-01,\n",
      "         -5.0040e-02,  1.4613e+00, -2.0549e-01,  3.3843e-01, -3.0057e-01,\n",
      "          3.8685e-01,  1.4873e+00,  6.0566e-01, -2.3470e-01, -4.7638e-01,\n",
      "          8.3751e-01, -8.8683e-01, -2.4578e-01, -5.9779e-01,  1.7673e-01,\n",
      "          6.3682e-01,  6.5929e-01,  2.5210e-02,  4.5588e-01,  3.1005e+00,\n",
      "          7.2731e-01, -2.0554e+00,  9.9634e-01,  2.2358e-01,  2.0443e+00,\n",
      "         -1.2899e+00,  1.3707e+00,  4.8510e-01, -1.7278e+00,  1.8220e+00,\n",
      "          1.1213e+00,  7.2746e-01,  1.9526e-01,  5.8423e-01, -6.4432e-01,\n",
      "         -9.2855e-01,  5.3207e-01, -4.2801e-01, -1.0787e-01, -4.1583e-01,\n",
      "          1.4100e+00,  2.3853e-01, -5.3985e-01,  3.7699e-01,  5.6751e-01,\n",
      "         -2.2168e-01,  5.0146e-01, -1.0218e+00, -1.3175e+00, -3.0777e-01,\n",
      "         -1.5587e+00,  1.1246e+00,  4.8878e-01,  6.0633e-01,  1.8745e-01,\n",
      "         -1.2168e+00,  1.0515e-02, -1.5926e+00, -2.3698e-01, -2.2997e-01,\n",
      "         -1.8406e-01, -8.9342e-01,  2.9728e-01, -4.7906e-01, -2.8074e-01,\n",
      "         -6.9657e-01, -1.8938e+00, -4.3830e-01,  3.5173e-01, -8.1242e-01,\n",
      "         -8.4519e-01,  7.5213e-01, -1.1004e+00, -6.7715e-01, -3.1526e-01,\n",
      "         -2.5546e-01,  1.0980e+00, -1.1844e+00, -4.0520e-01, -4.4024e-01,\n",
      "         -1.1878e+00, -8.4902e-02, -2.4325e-02, -2.4200e+00, -7.1419e-01,\n",
      "          1.0375e-01,  8.6903e-02, -1.3852e+00,  1.6532e-01, -4.6331e-01,\n",
      "          2.6375e-01,  2.9243e-01,  1.0531e-01, -1.4172e+00, -1.2406e+00,\n",
      "          8.7035e-01, -4.3418e-01,  1.6166e+00, -5.3330e-01, -4.6801e-01,\n",
      "         -1.4215e-01,  1.7071e+00, -6.2368e-01,  8.0528e-01,  3.3026e-01,\n",
      "         -1.6399e-01,  3.0122e-01, -1.1699e+00, -1.8625e-01,  4.7146e-01,\n",
      "          8.0474e-01,  3.4317e-01, -5.7529e-01,  7.0477e-01, -1.3925e+00,\n",
      "         -8.1355e-01,  3.2372e-01, -3.1535e-01,  2.8887e+00, -1.0479e+00,\n",
      "         -7.2910e-01, -8.4324e-01,  5.3719e-01, -6.0662e-01, -1.4305e+00,\n",
      "         -5.1038e-01, -3.3012e-01,  1.1537e+00,  9.0799e-01,  9.3786e-01,\n",
      "         -1.3058e+00, -8.9830e-02, -1.0207e+00, -1.1323e+00, -1.3512e+00,\n",
      "          1.6003e-01,  6.0234e-01, -2.9118e-01,  1.0631e-01,  7.2431e-01,\n",
      "          8.9217e-01, -9.5308e-01, -5.8970e-01, -3.4830e-01, -6.6559e-01,\n",
      "          8.1012e-01, -1.5491e+00, -1.3421e+00,  1.2124e-01, -9.6859e-01,\n",
      "          1.1442e-01, -1.9983e-01, -1.8283e+00,  3.7139e-01,  7.5871e-01,\n",
      "          1.0983e+00, -7.7448e-01, -9.6181e-01,  3.5719e-02, -2.5380e-01,\n",
      "          6.2985e-01,  1.2024e+00, -2.9270e+00,  3.0691e-01,  1.4767e+00,\n",
      "          1.5123e+00, -9.3521e-03, -7.1146e-02,  2.6869e+00,  8.5080e-02,\n",
      "         -7.4661e-01, -1.4812e-01, -7.7811e-01, -5.8576e-01, -6.2092e-01,\n",
      "          1.1830e+00, -1.4520e+00, -2.1610e+00,  4.1565e-01,  5.0341e-01,\n",
      "         -4.7215e-01,  1.2383e+00, -3.1397e-01,  1.2253e+00,  1.3842e-01,\n",
      "          1.2755e+00,  1.9886e-02, -1.3490e+00, -1.0453e+00,  1.3758e+00,\n",
      "         -1.0324e+00,  1.8680e+00,  1.9112e+00, -3.9643e-03,  9.1913e-01,\n",
      "          3.3188e-01,  2.0639e+00, -2.3337e-01,  9.2037e-01, -9.2368e-01,\n",
      "         -4.6981e-01,  2.0085e-02, -2.0580e-01, -1.1560e+00, -5.8195e-01,\n",
      "          1.5646e-01,  2.4936e+00,  7.3484e-01, -1.9472e-01,  2.7694e-01,\n",
      "          3.9776e-01,  6.9010e-01, -1.6883e+00,  4.9083e-01,  1.5284e+00,\n",
      "          2.2416e-01,  5.6412e-01, -3.5645e-02,  2.8868e-01,  1.2466e+00,\n",
      "         -2.7168e-01, -1.9334e-02, -6.7440e-01,  1.0340e+00,  5.8547e-01,\n",
      "         -7.1272e-01,  2.6056e-01,  4.7644e-01, -8.8546e-01,  4.2820e-01,\n",
      "          6.3476e-01, -2.4010e-01, -6.5174e-01,  1.3636e-01,  9.6296e-01,\n",
      "         -7.3361e-01, -1.0940e+00, -1.5990e-01, -1.4142e-01,  9.1874e-01,\n",
      "         -4.0032e-02, -1.8288e+00, -1.5908e+00, -8.0703e-01, -4.6132e-02,\n",
      "         -3.2818e-01, -1.1183e-01, -1.7843e+00,  8.2551e-03, -3.9773e-01,\n",
      "         -9.3057e-01, -1.9793e+00,  8.2172e-01, -5.3548e-02,  1.1973e+00,\n",
      "         -1.8109e-01,  6.3859e-01, -2.7579e-01,  1.1859e+00,  1.0975e+00,\n",
      "         -1.2005e+00,  5.6994e-01, -1.2699e-01, -1.7366e-02, -7.3948e-02,\n",
      "          5.2039e-01, -1.7542e+00,  2.9119e-01,  1.1883e-01, -2.3744e-01,\n",
      "         -1.3359e+00,  3.2652e+00, -6.5341e-01, -1.0649e+00,  2.2246e-01,\n",
      "         -1.0935e+00,  1.2738e+00,  2.1517e-01,  2.7246e-01, -5.5896e-01,\n",
      "          1.2733e+00, -7.7260e-01, -3.1291e-01,  1.8634e-01,  4.8675e-01,\n",
      "         -4.5840e-01,  1.8445e+00, -9.5196e-03,  3.1357e-02,  1.1344e+00,\n",
      "         -7.0176e-01,  1.0455e+00, -3.0351e-01,  4.8045e-01, -4.8306e-01,\n",
      "         -8.4286e-02,  3.1595e-01, -1.0934e+00, -1.2160e+00, -1.1366e+00,\n",
      "          6.0238e-01, -9.5942e-01, -2.0425e+00,  6.4186e-03, -8.6983e-02,\n",
      "          1.2246e+00,  4.5437e-01, -4.8415e-01, -5.5595e-01, -5.4599e-01,\n",
      "         -9.2424e-01, -8.1890e-01, -1.5012e+00, -7.8283e-01, -2.7258e-01,\n",
      "         -1.1890e+00,  1.7431e-02, -1.3991e+00, -1.0182e+00,  5.3321e-02,\n",
      "          7.0490e-01,  3.4747e-02,  1.1409e+00, -1.2265e+00,  1.2449e+00,\n",
      "          4.7955e-01,  9.1545e-02,  1.2814e+00, -5.5889e-01,  5.3119e-01,\n",
      "         -1.2034e-01,  1.2072e+00,  6.8949e-01,  1.8610e-01, -3.9544e-01,\n",
      "          1.5685e+00,  6.4871e-01, -1.1327e+00, -4.9918e-01, -5.5221e-01,\n",
      "          7.7258e-01,  1.3198e+00,  7.9242e-01, -1.3616e+00, -1.1219e-01,\n",
      "         -1.9543e+00, -7.9261e-01,  1.1555e-01, -3.4650e-01,  7.4192e-01,\n",
      "          1.7601e+00,  8.9348e-01,  1.4418e+00, -1.2120e-01,  6.1568e-01,\n",
      "          1.4255e+00, -2.8412e-01, -6.2764e-01, -2.9341e-01, -5.5256e-01,\n",
      "         -2.4540e-01, -4.9754e-03,  1.1323e+00,  2.6965e-01, -5.1704e-01,\n",
      "          7.5237e-01,  5.3353e-01, -3.1314e-02,  7.5572e-01,  1.4670e+00,\n",
      "         -8.7957e-01, -1.4097e+00, -9.1128e-01,  6.8851e-01, -2.0470e-01,\n",
      "         -1.1854e+00, -7.8616e-01,  5.0312e-01, -1.0611e+00, -1.1096e-01,\n",
      "          1.7540e+00,  1.0494e+00, -8.9969e-01,  3.3242e-02,  1.2389e+00,\n",
      "         -9.9087e-01,  1.3209e+00, -1.4996e+00,  3.2989e-02, -8.8659e-01,\n",
      "         -6.8785e-01, -1.3998e+00,  2.0764e+00, -2.0980e+00,  1.6146e-01,\n",
      "         -1.2580e+00,  9.6912e-01, -1.6491e+00,  1.5729e+00,  4.5854e-01,\n",
      "          1.6808e-01, -3.1327e-01, -2.1441e+00, -7.8369e-01, -6.8002e-01,\n",
      "          8.5499e-01,  1.9504e+00, -2.8668e-01,  5.8091e-01, -6.3091e-01,\n",
      "          1.4871e+00, -6.0081e-01, -3.6225e-01, -4.0831e-01,  2.9913e-01,\n",
      "          4.3146e-01,  6.9413e-02, -1.5877e+00,  6.2838e-01, -1.8964e-01,\n",
      "         -1.6913e+00, -3.0669e-01, -6.1141e-01,  4.7317e-02, -4.6321e-01,\n",
      "          3.8399e-02, -1.8148e+00,  3.8953e-01,  8.4111e-01,  7.9447e-01,\n",
      "          3.3379e-01,  1.6086e-01,  5.2571e-01, -6.7355e-01,  6.4453e-01,\n",
      "         -1.7278e-01,  4.4687e-01,  3.0303e-01, -1.3927e-01,  4.4876e-01,\n",
      "         -1.0351e+00, -2.0019e-01,  1.0120e+00,  6.8570e-01,  1.4468e+00,\n",
      "         -1.0966e+00, -1.4932e-01,  1.3029e-01, -6.6201e-02,  2.3123e-01,\n",
      "          7.6412e-01, -6.1260e-02,  6.1619e-01,  3.3644e-01, -9.5744e-01,\n",
      "          1.0394e-01,  1.5322e+00,  1.2512e-01, -1.7154e+00,  1.0098e-01,\n",
      "         -3.6368e-01,  3.9178e-01, -6.5862e-01, -2.5422e-02, -1.8853e-01,\n",
      "          4.3859e-02,  5.7301e-01, -1.4729e+00, -2.2356e+00,  4.6355e-02,\n",
      "         -2.9697e-01,  2.4675e-01,  6.7765e-01, -1.4243e-03, -1.1563e-01,\n",
      "          2.9768e-02,  6.9144e-01, -2.7188e-01,  8.0146e-01, -1.6700e-01,\n",
      "         -6.0974e-01, -5.7308e-01,  5.3267e-01, -2.1876e-01,  1.5574e+00,\n",
      "          1.5494e-01, -4.6272e-01, -1.0366e+00,  1.1438e+00,  3.3658e-01,\n",
      "          1.1106e+00, -1.9085e-01,  1.6942e-02,  5.8804e-01,  1.0895e+00,\n",
      "          1.1350e+00,  4.7290e-01,  1.8265e-01, -1.1213e+00,  8.3183e-02,\n",
      "          9.7941e-01, -1.3401e-01,  1.5436e+00, -9.0642e-01,  1.3243e+00,\n",
      "          5.4150e-01,  1.1907e+00, -2.7873e-01,  5.2411e-01, -1.2936e+00,\n",
      "          4.7965e-01, -3.5300e-01,  3.5365e-01, -4.2963e-01,  3.0933e-01,\n",
      "          8.6841e-01,  1.1611e+00,  1.3005e+00,  5.7076e-01, -1.0256e-02,\n",
      "          3.7241e-01,  1.0659e+00, -1.8515e+00,  2.6886e+00,  7.3652e-01,\n",
      "         -4.2411e-01,  4.0027e-02,  8.2388e-01, -1.3583e+00, -5.6193e-01,\n",
      "         -8.6465e-01, -2.2171e-01, -5.3688e-01, -5.2553e-02, -1.1174e-01,\n",
      "         -1.0929e-01,  1.2083e-01,  3.3343e-01,  4.0783e-02,  6.3978e-01,\n",
      "         -6.2854e-01,  6.0815e-01, -8.6627e-01,  2.9967e-02,  6.9514e-01,\n",
      "         -3.4696e-01, -1.1095e+00,  1.5994e-01, -2.3295e-01, -6.1051e-01,\n",
      "          9.9881e-01, -9.2890e-02,  4.7232e-01,  1.4375e+00,  5.2045e-01,\n",
      "          7.9730e-01, -8.6011e-02, -1.3253e+00, -1.1950e+00,  1.1274e+00,\n",
      "          7.3447e-02, -1.1783e-01,  1.2348e-01,  1.8558e-01, -5.8009e-01,\n",
      "          9.3397e-01,  1.7597e-01,  1.5111e-01, -1.4128e+00, -1.8658e-01,\n",
      "          1.3781e+00, -6.5032e-01,  4.5408e-02, -3.0792e-01,  6.0292e-01,\n",
      "         -2.2072e-01, -3.2255e-01,  5.4674e-01,  5.9536e-01,  1.9764e-01,\n",
      "         -9.8669e-02, -8.6243e-01,  7.8120e-01, -1.0594e+00, -1.1400e+00,\n",
      "         -6.3453e-01, -3.9210e-01,  3.8428e-01, -1.4478e-01, -1.0242e+00,\n",
      "          6.9818e-01,  9.2548e-01,  1.7437e+00, -3.5442e-01,  1.5650e+00,\n",
      "         -2.1335e-01, -2.9241e+00, -8.0016e-01,  2.8609e-01, -1.1693e+00,\n",
      "         -1.0514e-01,  4.1642e-01,  3.7043e-01, -6.2749e-01,  1.8118e-01,\n",
      "          5.5452e-01,  8.4362e-01, -5.2109e-02,  7.2523e-01, -8.3199e-01,\n",
      "          1.1351e+00, -9.9980e-02, -2.3536e-01, -7.5398e-01,  1.1050e-01,\n",
      "         -5.4216e-01,  3.5950e-01, -6.3467e-02,  1.1963e+00, -3.5328e-01,\n",
      "         -6.1554e-01, -8.6853e-01, -1.3206e+00]]), 'all': tensor([[[ 0.4762, -0.0996,  1.5029,  ..., -0.6155, -0.8685, -1.3206],\n",
      "         [ 0.4459,  1.3973,  1.0654,  ...,  1.2634, -0.6420, -0.6596],\n",
      "         [ 0.2928,  0.7041,  1.0459,  ...,  0.8337, -1.0403, -0.6151],\n",
      "         ...,\n",
      "         [-0.7214, -0.3007,  1.8384,  ...,  0.2925, -0.8894, -0.0785],\n",
      "         [ 0.4214, -0.3514,  2.0934,  ...,  0.0531, -0.9947,  0.2817],\n",
      "         [ 0.7228,  0.0380,  1.1926,  ..., -0.7180, -1.1438, -0.7053]]])}\n",
      "CLS token shape: torch.Size([1, 768])\n",
      "All token embeddings shape: torch.Size([1, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "from architecture.vit_architectire import VIT_ARCHITECTURE\n",
    "from configs.cnn_branch_config import cnn_experiment_1\n",
    "\n",
    "vit_model = VIT_ARCHITECTURE(cnn_experiment_1['model_args']['model_name'])\n",
    "\n",
    "\n",
    "vit_out = vit_model.extract_features(\"./Blur.png\")\n",
    "print(vit_out)\n",
    "print(\"CLS token shape:\", vit_out['cls'].shape)\n",
    "print(\"All token embeddings shape:\", vit_out['all'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42029efd",
   "metadata": {},
   "source": [
    "### Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc563cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0304, 0.0292, 0.0332,  ..., 0.0699, 0.0732, 0.0828],\n",
      "          [0.0589, 0.0623, 0.0616,  ..., 0.0773, 0.0772, 0.0744],\n",
      "          [0.0802, 0.0805, 0.0741,  ..., 0.0614, 0.0705, 0.0488],\n",
      "          ...,\n",
      "          [0.0501, 0.0389, 0.0336,  ..., 0.0425, 0.0520, 0.0568],\n",
      "          [0.0519, 0.0567, 0.0691,  ..., 0.0674, 0.0537, 0.0545],\n",
      "          [0.0641, 0.0537, 0.0687,  ..., 0.0112, 0.0101, 0.0069]],\n",
      "\n",
      "         [[0.0040, 0.0103, 0.0103,  ..., 0.0125, 0.0354, 0.0183],\n",
      "          [0.0359, 0.0223, 0.0256,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0354, 0.0315, 0.0311,  ..., 0.0612, 0.0576, 0.0594],\n",
      "          [0.0757, 0.0508, 0.0477,  ..., 0.0830, 0.0758, 0.0760],\n",
      "          [0.0706, 0.0792, 0.0621,  ..., 0.0520, 0.0537, 0.0472],\n",
      "          ...,\n",
      "          [0.0417, 0.0334, 0.0293,  ..., 0.0245, 0.0361, 0.0377],\n",
      "          [0.0469, 0.0503, 0.0444,  ..., 0.0364, 0.0310, 0.0405],\n",
      "          [0.0492, 0.0568, 0.0514,  ..., 0.0112, 0.0113, 0.0106]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0110, 0.0166, 0.0054,  ..., 0.0153, 0.0000, 0.0000],\n",
      "          [0.0174, 0.0159, 0.0071,  ..., 0.0162, 0.0204, 0.0201],\n",
      "          [0.0098, 0.0132, 0.0307,  ..., 0.0198, 0.0126, 0.0116],\n",
      "          ...,\n",
      "          [0.0239, 0.0179, 0.0220,  ..., 0.0297, 0.0201, 0.0174],\n",
      "          [0.0240, 0.0333, 0.0197,  ..., 0.0364, 0.0296, 0.0330],\n",
      "          [0.0273, 0.0153, 0.0182,  ..., 0.0115, 0.0121, 0.0115]],\n",
      "\n",
      "         [[0.0186, 0.0010, 0.0027,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Fused feat shape is: torch.Size([1, 512, 120, 120])\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Remove [CLS] token\n",
    "transformer_feat = vit_out[\"all\"][:, 1:, :]   # [1, 196, 768]\n",
    "\n",
    "# STEP 2: Reshape to [1, 768, 14, 14]\n",
    "transformer_feat = transformer_feat.view(1, 14, 14, 768).permute(0, 3, 1, 2)  # [1, 768, 14, 14]\n",
    "\n",
    "# STEP 3: Upsample to match CNN spatial size (120x120)\n",
    "transformer_feat = functional.interpolate(transformer_feat, size=(120, 120), mode='bilinear', align_corners=False)  # [1, 768, 120, 120]\n",
    "\n",
    "# STEP 4: Reshape CNN output to [1, 512, 120, 120]\n",
    "cnn_feat = cnn_out.view(1, 512, 120, 120)\n",
    "\n",
    "# STEP 5: Match channel dims (768 → 512) using 1x1 conv\n",
    "conv1x1 = nn.Conv2d(768, 512, kernel_size=1)\n",
    "transformer_feat_projected = conv1x1(transformer_feat)  # [1, 512, 120, 120]\n",
    "\n",
    "# STEP 6: Element-wise multiplication (weighted attention)\n",
    "fused_feat = cnn_feat * torch.sigmoid(transformer_feat_projected)\n",
    "\n",
    "print(fused_feat)\n",
    "print(f\"Fused feat shape is: {fused_feat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d120216a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_tensor: torch.Size([3, 120, 120])\n",
      "[[[123 130 126]\n",
      "  [123 130 126]\n",
      "  [123 130 126]\n",
      "  ...\n",
      "  [123 130 126]\n",
      "  [123 130 126]\n",
      "  [123 130 125]]\n",
      "\n",
      " [[123 130 126]\n",
      "  [123 130 126]\n",
      "  [123 130 126]\n",
      "  ...\n",
      "  [123 130 126]\n",
      "  [123 130 126]\n",
      "  [123 129 126]]\n",
      "\n",
      " [[123 130 126]\n",
      "  [123 130 126]\n",
      "  [123 130 126]\n",
      "  ...\n",
      "  [123 130 126]\n",
      "  [123 130 126]\n",
      "  [123 129 126]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[123 130 126]\n",
      "  [123 130 126]\n",
      "  [123 130 126]\n",
      "  ...\n",
      "  [123 130 126]\n",
      "  [123 130 126]\n",
      "  [123 129 126]]\n",
      "\n",
      " [[123 130 126]\n",
      "  [123 130 126]\n",
      "  [123 130 126]\n",
      "  ...\n",
      "  [123 130 126]\n",
      "  [123 130 126]\n",
      "  [122 130 126]]\n",
      "\n",
      " [[123 130 126]\n",
      "  [123 129 126]\n",
      "  [123 129 126]\n",
      "  ...\n",
      "  [123 129 126]\n",
      "  [123 129 126]\n",
      "  [123 129 126]]]\n"
     ]
    }
   ],
   "source": [
    "from architecture.reconstruction_head import RECONSTRUCTION_HEAD\n",
    "\n",
    "recon_head = RECONSTRUCTION_HEAD(512, 3)\n",
    "\n",
    "output_image = recon_head(fused_feat)\n",
    "\n",
    "image_tensor = output_image.squeeze(0)\n",
    "print(f\"image_tensor: {image_tensor.shape}\")\n",
    "\n",
    "image_tensor = (image_tensor + 1)/2.0\n",
    "img_tensor = image_tensor.clamp(0, 1)\n",
    "\n",
    "# Step 3: Convert to numpy and reshape\n",
    "img_np = img_tensor.mul(255).byte().permute(1, 2, 0).cpu().numpy()  # [120, 120, 3]\n",
    "print(img_np)\n",
    "\n",
    "# Step 4: Convert to PIL Image and show\n",
    "img_pil = Image.fromarray(img_np)\n",
    "img_pil.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce37e98c",
   "metadata": {},
   "source": [
    "### CNN-ViT Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c57e9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/HLCV/lib/python3.12/site-packages/transformers/models/vit/feature_extraction_vit.py:30: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to eager attention. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "vit_attention_map.shape: torch.Size([1, 197, 197])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0270,  0.0265,  0.0258,  ...,  0.0261,  0.0260,  0.0257],\n",
       "          [ 0.0257,  0.0261,  0.0252,  ...,  0.0255,  0.0256,  0.0270],\n",
       "          [ 0.0250,  0.0254,  0.0245,  ...,  0.0249,  0.0251,  0.0270],\n",
       "          ...,\n",
       "          [ 0.0249,  0.0253,  0.0245,  ...,  0.0249,  0.0250,  0.0270],\n",
       "          [ 0.0252,  0.0253,  0.0246,  ...,  0.0250,  0.0254,  0.0270],\n",
       "          [ 0.0258,  0.0246,  0.0243,  ...,  0.0246,  0.0251,  0.0281]],\n",
       "\n",
       "         [[ 0.0375,  0.0394,  0.0385,  ...,  0.0387,  0.0397,  0.0404],\n",
       "          [ 0.0382,  0.0391,  0.0384,  ...,  0.0384,  0.0404,  0.0417],\n",
       "          [ 0.0373,  0.0382,  0.0376,  ...,  0.0377,  0.0396,  0.0415],\n",
       "          ...,\n",
       "          [ 0.0372,  0.0380,  0.0373,  ...,  0.0375,  0.0394,  0.0414],\n",
       "          [ 0.0385,  0.0391,  0.0383,  ...,  0.0385,  0.0398,  0.0416],\n",
       "          [ 0.0379,  0.0391,  0.0388,  ...,  0.0387,  0.0398,  0.0389]],\n",
       "\n",
       "         [[-0.0303, -0.0317, -0.0312,  ..., -0.0310, -0.0320, -0.0293],\n",
       "          [-0.0310, -0.0314, -0.0307,  ..., -0.0304, -0.0312, -0.0305],\n",
       "          [-0.0302, -0.0305, -0.0299,  ..., -0.0297, -0.0306, -0.0304],\n",
       "          ...,\n",
       "          [-0.0303, -0.0306, -0.0299,  ..., -0.0298, -0.0305, -0.0303],\n",
       "          [-0.0315, -0.0322, -0.0315,  ..., -0.0313, -0.0319, -0.0308],\n",
       "          [-0.0265, -0.0252, -0.0250,  ..., -0.0250, -0.0253, -0.0292]]]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from architecture.cnn_vit_hybrid_architecture import CNN_VIT_HYBRID_ARCHITECTURE\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "raw_image = Image.open(\"./Blur.png\").convert('RGB')\n",
    "image = transform(raw_image)\n",
    "\n",
    "\n",
    "model = CNN_VIT_HYBRID_ARCHITECTURE()\n",
    "model(image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321ea90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HLCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
