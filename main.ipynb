{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e286120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# Imports\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd380b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# System path for imports\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "PROJECT_ROOT='./'\n",
    "import sys\n",
    "sys.path.append(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f18e8e",
   "metadata": {},
   "source": [
    "### Branch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb3c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0149, 0.0157,  ..., 0.5947, 0.5671, 0.4482]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 401408])\n",
      "torch.Size([512, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# Driver code\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "from architecture.cnn_architecture import CNN_ARCHITECTURE\n",
    "from configs.cnn_branch_config import cnn_experiment_1\n",
    "\n",
    "model = CNN_ARCHITECTURE(cnn_experiment_1['model_args']['input_size'], cnn_experiment_1['model_args']['hidden_layers'], cnn_experiment_1['model_args']['activation'], cnn_experiment_1['model_args']['norm_layer'], cnn_experiment_1['model_args']['drop_prob'])\n",
    "model.eval()\n",
    "\n",
    "input = torch.randn(1,3,224,224)\n",
    "\n",
    "final_features = model(input)\n",
    "\n",
    "print(final_features)\n",
    "print(final_features.shape)\n",
    "\n",
    "features_in_shape = final_features.view(512, 28, 28)\n",
    "print(features_in_shape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2650c44d",
   "metadata": {},
   "source": [
    "### Branch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feea971c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "VIT_ARCHITECTURE.__init__() missing 1 required positional argument: 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01marchitecture\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvit_architectire\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VIT_ARCHITECTURE\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconfigs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcnn_branch_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cnn_experiment_1\n\u001b[0;32m----> 4\u001b[0m vit_model \u001b[38;5;241m=\u001b[39m VIT_ARCHITECTURE(cnn_experiment_1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_args\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m vit_features \u001b[38;5;241m=\u001b[39m vit_model\u001b[38;5;241m.\u001b[39mextract_features(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLS token shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, vit_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mTypeError\u001b[0m: VIT_ARCHITECTURE.__init__() missing 1 required positional argument: 'model_name'"
     ]
    }
   ],
   "source": [
    "from architecture.vit_architectire import VIT_ARCHITECTURE\n",
    "from configs.cnn_branch_config import cnn_experiment_1\n",
    "\n",
    "vit_model = VIT_ARCHITECTURE(cnn_experiment_1['model_args']['model_name'])\n",
    "\n",
    "vit_features = vit_model.extract_features(input)\n",
    "print(\"CLS token shape:\", vit_features['cls'].shape)\n",
    "print(\"All token embeddings shape:\", vit_features['all'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5f9555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HLCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
